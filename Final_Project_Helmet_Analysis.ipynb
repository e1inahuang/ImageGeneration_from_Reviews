{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# VICTGOAL Bike Helmet: Review Analysis & Image Generation\n",
                "\n",
                "This notebook consolidates the analysis for the Final Project, covering:\n",
                "1.  **Q2:** Analyzing customer reviews using Embeddings, Clustering, and LLM Feature Extraction.\n",
                "2.  **Q3:** Generating product images using Stable Diffusion based on the extracted insights."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.metrics import silhouette_score\n",
                "import faiss\n",
                "from dotenv import load_dotenv\n",
                "from openai import OpenAI\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
                "\n",
                "# Load Reviews\n",
                "df = pd.read_csv('reviews.csv')\n",
                "print(f\"Loaded {len(df)} reviews\")\n",
                "\n",
                "# Clean Data\n",
                "df['review_text'] = df['tl-m'].fillna('')\n",
                "reviews = df['review_text'].tolist()\n",
                "print(f\"Processed {len(reviews)} valid reviews\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Embedding & Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Embeddings\n",
                "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "embeddings = model.encode(reviews)\n",
                "print(\"Embeddings generated shape:\", embeddings.shape)\n",
                "\n",
                "# K-Means Clustering\n",
                "num_clusters = 8\n",
                "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
                "cluster_labels = kmeans.fit_predict(embeddings)\n",
                "df['cluster'] = cluster_labels\n",
                "\n",
                "# Visualize Distribution\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.countplot(x='cluster', data=df, palette='viridis')\n",
                "plt.title('Review Cluster Distribution')\n",
                "plt.xlabel('Cluster ID')\n",
                "plt.ylabel('Number of Reviews')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: LLM Feature Extraction (RAG)\n",
                "We use FAISS to retrieve the most relevant reviews and feed them to GPT-4o to extract visual features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build FAISS Index\n",
                "dimension = embeddings.shape[1]\n",
                "index = faiss.IndexFlatL2(dimension)\n",
                "index.add(embeddings.astype('float32'))\n",
                "\n",
                "# Search for visual details\n",
                "query = \"visual appearance design materials aesthetic look style\"\n",
                "query_vector = model.encode([query])\n",
                "k = 500\n",
                "D, I = index.search(query_vector.astype('float32'), k)\n",
                "relevant_reviews = [reviews[i] for i in I[0]]\n",
                "\n",
                "# Construct Prompt for GPT-4o\n",
                "analysis_prompt = f\"\"\"\n",
                "Analyze the following 500 reviews for the VICTGOAL Bike Helmet.\n",
                "Extract the following details in JSON format:\n",
                "1. Design (Shape, Style, Vibe)\n",
                "2. Materials (Shell, Liner, Finish)\n",
                "3. Key Features (Visor, Goggles, Light)\n",
                "4. Color Scheme\n",
                "5. A detailed IMAGE PROMPT for a diffusion model.\n",
                "\n",
                "Reviews:\n",
                "{relevant_reviews[:10]} ... (truncated for brevity)\n",
                "\"\"\"\n",
                "\n",
                "print(\"Prompt constructed. (Skipping actual API call in notebook to save credits, loading cached result...)\")\n",
                "\n",
                "# Load Cached Features\n",
                "if os.path.exists('helmet_extracted_features.json'):\n",
                "    with open('helmet_extracted_features.json', 'r') as f:\n",
                "        features = json.load(f)\n",
                "    print(json.dumps(features, indent=2))\n",
                "else:\n",
                "    print(\"Cached features not found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Image Generation (Local)\n",
                "Using Stable Diffusion v1.5 and OpenJourney to visualize the extracted prompts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from diffusers import StableDiffusionPipeline\n",
                "from IPython.display import Image, display\n",
                "\n",
                "# Prompts\n",
                "prompts = [\n",
                "    {\"id\": \"p1_reviews\", \"desc\": \"Review-Based\", \"text\": \"...futuristic design with magnetic goggles...\"},\n",
                "    {\"id\": \"p2_specs\", \"desc\": \"Specs-Based\", \"text\": \"...dual-tone fluorescent yellow and black...\"},\n",
                "    {\"id\": \"p3_action\", \"desc\": \"Action Shot\", \"text\": \"...cinematic action shot...\"}\n",
                "]\n",
                "\n",
                "# Code to generate (Commented out to prevent auto-run)\n",
                "\"\"\"\n",
                "model_id = \"prompthero/openjourney\"\n",
                "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
                "pipe = pipe.to(\"mps\")\n",
                "\n",
                "for p in prompts:\n",
                "    image = pipe(p['text']).images[0]\n",
                "    image.save(f\"q3_generated_images/model2_openjourney_{p['id']}.png\")\n",
                "\"\"\"\n",
                "\n",
                "print(\"Images generated locally. Displaying results below:\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generated Images Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display Images\n",
                "import glob\n",
                "images = glob.glob(\"q3_generated_images/*.png\")\n",
                "for img_path in sorted(images):\n",
                "    print(f\"Displaying: {img_path}\")\n",
                "    display(Image(filename=img_path, width=400))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}